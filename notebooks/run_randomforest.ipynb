{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[WinError 1455] The paging file is too small for this operation to complete. Error loading \"C:\\Users\\Jiajun\\Desktop\\download-project\\.download-project\\lib\\site-packages\\torch\\lib\\caffe2_detectron_ops_gpu.dll\" or one of its dependencies.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-3e552465c94a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensemble\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0msrc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mload_annotation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mload_data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msrc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jiajun\\desktop\\download-project\\src\\data\\load_data.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msqlite3\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msignal\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\download-project\\.download-project\\lib\\site-packages\\torch\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    115\u001b[0m                 \u001b[0merr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mWinError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlast_error\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m                 \u001b[0merr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrerror\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;34mf' Error loading \"{dll}\" or one of its dependencies.'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 117\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    118\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mres\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m                 \u001b[0mis_loaded\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: [WinError 1455] The paging file is too small for this operation to complete. Error loading \"C:\\Users\\Jiajun\\Desktop\\download-project\\.download-project\\lib\\site-packages\\torch\\lib\\caffe2_detectron_ops_gpu.dll\" or one of its dependencies."
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from src.data import load_annotation, load_data\n",
    "from src.utils.train import train_test_split\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on 117 cases, [2021, 2005, 1918, 2027, 2015] ...\n",
      "Testing  on 30 cases, [1802, 1806, 1830, 1831, 1836] ...\n"
     ]
    }
   ],
   "source": [
    "# config\n",
    "DATAFRAME_PATH = \"../data/raw/data_frames\"\n",
    "ANNOTATION_PATH = \"../data/processed/Annotation.csv\"\n",
    "CATEGORY = \"Urination\"\n",
    "THRESHOLD = 0.3\n",
    "\n",
    "FEATURE_NAMES = ['Min', 'Max', 'Median', 'Mean', 'LogVariance', 'LinearTrend']\n",
    "SOURCES = ['TotalWeight', 'WaterDistance', 'AudioDelay', 'RadarSum', 'AudioDelay2', 'AudioDelay4']\n",
    "CATEGORY = 'Urination'\n",
    "\n",
    "ANNOTATIONS = load_annotation.get_annotation(ANNOTATION_PATH)\n",
    "USER_IDS = load_annotation.get_complete_ids(ANNOTATION_PATH, CATEGORY)\n",
    "TRAIN_IDS, TEST_IDS = train_test_split(USER_IDS)\n",
    "\n",
    "print (\"Training on {} cases, {} ...\".format(len(TRAIN_IDS), TRAIN_IDS[:5]))\n",
    "print (\"Testing  on {} cases, {} ...\".format(len(TEST_IDS), TEST_IDS[:5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_train_config = {\n",
    "    'USE_IDS': TRAIN_IDS,\n",
    "    'ANNOTATION_PATH': ANNOTATION_PATH,\n",
    "    'FEATURE_NAMES': FEATURE_NAMES,\n",
    "    'SOURCES': SOURCES,\n",
    "    'CATEGORY': CATEGORY\n",
    "}\n",
    "\n",
    "rf_test_config = {\n",
    "    'USE_IDS': TEST_IDS,\n",
    "    'ANNOTATION_PATH': ANNOTATION_PATH,\n",
    "    'FEATURE_NAMES': FEATURE_NAMES,\n",
    "    'SOURCES': SOURCES,\n",
    "    'CATEGORY': CATEGORY\n",
    "}\n",
    "\n",
    "dataset = {}\n",
    "dataset['train'] = load_data.RandomForestDataset(rf_train_config)\n",
    "dataset['test'] = load_data.RandomForestDataset(rf_test_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, train_y = dataset['train'].get_all_features_and_labels()\n",
    "test_x, test_y = dataset['test'].get_all_features_and_labels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification_result(model, testX, testY):\n",
    "    testYPredProb = model.predict_proba(testX)\n",
    "    testYPred = (testYPredProb[:, 1] > 0.5).astype(int)\n",
    "    print (classification_report(testY, testYPred))\n",
    "\n",
    "def variable_importance(trainX, model):\n",
    "    plt.bar(x = range(trainX.shape[1]), height = model.feature_importances_)\n",
    "    xticks_pos = np.arange(trainX.shape[1])\n",
    "    plt.xticks(xticks_pos, trainX.columns, rotation=45, ha = 'right')\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, plot_roc_curve\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators = 30, max_features = 15)\n",
    "rf.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"Training on {} cases, {} ...\".format(len(TRAIN_IDS), TRAIN_IDS[:5]))\n",
    "print (\"Testing  on {} cases, {} ...\".format(len(TEST_IDS), TEST_IDS[:5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variable importance\n",
    "plt.figure(figsize = (12, 6))\n",
    "variable_importance(train_x, rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import time\n",
    "\n",
    "timestr = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "with open(f\"../randomforest-{timestr}.pkl\", \"wb\") as f:\n",
    "    pickle.dump(rf, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"../randomforest-20210108-032342.pkl\", \"rb\") as f:\n",
    "    rf = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating user : 1919\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'predictions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-b5afab7d2eb5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[0mevaluation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mEvaluation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0meval_config\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mevaluation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_predicted_regions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[1;31m#X = evaluation.get_feature_and_label()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-9-4bac80dc07ba>\u001b[0m in \u001b[0;36mget_predicted_regions\u001b[1;34m(self, threshold)\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[0mprediction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeature\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m         \u001b[0mprediction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m         \u001b[0mregions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbooleanToRegions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mst\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     46\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mregions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'predictions' is not defined"
     ]
    }
   ],
   "source": [
    "DATAFRAME_PATH = \"../data/raw/data_frames\"\n",
    "ANNOTATION_PATH = \"../data/processed/Annotation.csv\"\n",
    "CATEGORY = \"Urination\"\n",
    "THRESHOLD = 0.3\n",
    "\n",
    "FEATURE_NAMES = ['Min', 'Max', 'Median', 'Mean', 'LogVariance', 'LinearTrend']\n",
    "SOURCES = ['TotalWeight', 'WaterDistance', 'AudioDelay', 'RadarSum', 'AudioDelay2', 'AudioDelay4']\n",
    "CATEGORY = 'Urination'\n",
    "\n",
    "eval_config = {\n",
    "    'USE_ID': 1919,\n",
    "    'SOURCES': SOURCES,\n",
    "    'FEATURE_NAMES': FEATURE_NAMES,\n",
    "    'CATEGORY': CATEGORY,\n",
    "    'MODEL': rf,\n",
    "    'ANNOTATION_PATH': ANNOTATION_PATH\n",
    "}\n",
    "\n",
    "evaluation = Evaluation(eval_config)\n",
    "X = evaluation.get_predicted_regions()\n",
    "#X = evaluation.get_feature_and_label()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def booleanToRegions(labels, start_time):\n",
    "    res = []\n",
    "    start = 1\n",
    "    while (start < len(labels)):\n",
    "        while (start < len(labels) and labels[start] == 0):\n",
    "            start += 1\n",
    "        if (start < len(labels) - 1):\n",
    "            end = start + 1\n",
    "            while (end < len(labels) and labels[end] == 1):\n",
    "                end += 1\n",
    "            res.append([start_time + start, start_time + end - 1])\n",
    "            start = end    \n",
    "    return res\n",
    "\n",
    "class Evaluation:\n",
    "    def __init__(self, eval_config):\n",
    "        self.use_id = eval_config['USE_ID']\n",
    "        self.sources = eval_config['SOURCES']\n",
    "        self.category = eval_config['CATEGORY']\n",
    "        self.feature_names = eval_config['FEATURE_NAMES']\n",
    "        self.model = eval_config['MODEL']\n",
    "        self.annotation_path = eval_config['ANNOTATION_PATH']\n",
    "    \n",
    "    def get_feature_and_label(self):\n",
    "        config = {\n",
    "            'USE_IDS': [self.use_id],\n",
    "            'ANNOTATION_PATH': self.annotation_path,\n",
    "            'FEATURE_NAMES': self.feature_names,\n",
    "            'SOURCES': self.sources,\n",
    "            'CATEGORY': self.category\n",
    "        }\n",
    "        return load_data.RandomForestDataset(config).get_all_features_and_labels()\n",
    "    \n",
    "    def get_annotated_regions(self):\n",
    "        annotations = load_annotation.get_annotation(self.annotation_path)\n",
    "        regions = annotations[use_i]\n",
    "        defecate_regions = [region[:2] for region in regions if region[2] == 'Defecation']\n",
    "        urinate_regions = [region[:2] for region in regions if region[2] == 'Urination']\n",
    "        return urinate_regions, defecate_regions\n",
    "    \n",
    "    def get_predicted_regions(self, threshold = 0.3):\n",
    "        feature, label = self.get_feature_and_label()\n",
    "        prediction = self.model.predict_proba(feature)\n",
    "        prediction = (prediction[:, 1] > threshold).astype(int)\n",
    "        regions = booleanToRegions(prediction, st)\n",
    "        return regions\n",
    "\n",
    "def PlotWithAnnotationPrediction(use_i, model, category, threshold = 0.3):\n",
    "    urinate_regions, defecate_regions = getAnnotatedRegions(use_i)\n",
    "    predicted_regions = getPredictedRegions(use_i, model, threshold)\n",
    "    totalweight = getTotalWeightsz(use_i)\n",
    "\n",
    "    fig, ax = plt.subplots(2, 1, figsize = (15, 2*2), sharex = True)\n",
    "    ax[0].plot(totalweight)\n",
    "    ax[0].title.set_text('{} : total weight'.format(use_i))\n",
    "    ax[0].set_ylim(totalweight.median() - 0.5, totalweight.median() + 0.5)\n",
    "    ax[1].plot(totalweight)\n",
    "    ax[1].title.set_text('{} : total weight'.format(use_i))\n",
    "    ax[1].set_ylim(totalweight.median() - 0.5, totalweight.median() + 0.5)\n",
    "    if category == \"Urination\":\n",
    "        regions = urinate_regions\n",
    "    else:\n",
    "        regions = defecate_regions\n",
    "        \n",
    "    for region in regions:\n",
    "        ax[0].axvspan(region[0], region[1] + 1, alpha=0.5, color='gold')\n",
    "    for region in predicted_regions:\n",
    "        ax[1].axvspan(region[0], region[1] + 1, alpha=0.5, color='red')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"evaluation/defecation_{}.jpg\".format(use_i))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PlotWithAnnotationPrediction(1919, rf, \"Urination\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".download-project",
   "language": "python",
   "name": ".download-project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
