{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code to visualize each use "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pylab as plt\n",
    "import librosa\n",
    "import librosa.display\n",
    "import load_toilet_data\n",
    "import pandas as pa\n",
    "import plot_data\n",
    "import plot_us\n",
    "import sqlite3\n",
    "import numpy as np\n",
    "import os\n",
    "import gc\n",
    "import pylab as pl\n",
    "from scipy.signal import hilbert, sosfiltfilt, butter\n",
    "from scipy import signal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run code block below to get ID numbers for every human use case of the device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ID,           date/time ,     user_id, stool #, urine #\n",
      " 1806, 2020-09-28 20:59:35 ,         Mnb,       1,       1\n",
      " 1807, 2020-09-28 21:47:47 ,       H6502,       1,       1\n",
      " 1808, 2020-09-28 23:14:57 ,       H6502,       0,       2\n",
      " 1817, 2020-10-01 23:06:00 ,       H6502,       2,       1\n",
      " 1818, 2020-10-02 00:37:24 ,       H6502,       0,       1\n",
      " 1826, 2020-10-15 05:43:04 ,        None,       0,       1\n",
      " 1828, 2020-10-15 06:45:09 ,       H6502,       0,       1\n",
      " 1829, 2020-10-15 08:25:53 ,       H6502,       0,       1\n",
      " 1830, 2020-10-18 01:09:38 ,       H6502,       1,       1\n",
      " 1831, 2020-10-18 01:26:33 ,         Mnb,       1,       1\n",
      " 1832, 2020-10-18 02:46:50 ,       H6502,       0,       1\n",
      " 1833, 2020-10-18 04:16:19 ,       H6502,       0,       1\n",
      " 1834, 2020-10-18 06:22:55 ,       H6502,       0,       1\n",
      " 1835, 2020-10-18 09:56:36 ,       H6502,       0,       1\n",
      " 1836, 2020-10-18 20:31:56 ,       H6502,       0,       1\n",
      " 1839, 2020-10-20 14:49:55 ,         Mnb,       1,       1\n",
      " 1841, 2020-10-20 17:37:02 ,        None,       0,       1\n",
      " 1845, 2020-10-20 20:42:00 ,       H6502,       0,       1\n",
      " 1854, 2020-10-22 12:26:57 ,         Mnb,       1,       1\n",
      " 1855, 2020-10-22 14:52:36 ,        None,       0,       0\n",
      " 1861, 2020-10-23 11:23:01 ,       H6502,       2,       1\n",
      " 1862, 2020-10-23 12:40:29 ,        None,       1,       1\n",
      " 1869, 2020-10-23 18:26:10 ,         Mnb,       0,       1\n",
      " 1870, 2020-10-26 12:23:27 ,         Mnb,       1,       1\n",
      " 1871, 2020-10-26 14:38:04 ,       H6502,       0,       1\n",
      " 1872, 2020-10-26 15:11:59 ,         Mnb,       0,       0\n",
      " 1874, 2020-10-27 11:28:37 ,       H6502,       0,       1\n",
      " 1875, 2020-10-27 11:52:45 ,         Mnb,       1,       2\n",
      " 1876, 2020-10-27 13:20:36 ,       H6502,       0,       1\n",
      " 1877, 2020-10-27 15:03:21 ,         Mnb,       0,       1\n",
      " 1878, 2020-10-27 15:48:13 ,       H6502,       0,       2\n",
      " 1879, 2020-10-27 17:23:16 ,       H6502,       0,       1\n",
      " 1880, 2020-10-27 20:41:42 ,       H6502,       0,       1\n",
      " 1881, 2020-10-28 12:42:09 ,         Mnb,       3,       4\n",
      " 1882, 2020-10-28 12:56:12 ,       H6502,       2,       1\n",
      " 1883, 2020-10-28 14:38:43 ,       H6502,       0,       1\n",
      " 1884, 2020-10-28 16:23:02 ,       H6502,       0,       1\n",
      " 1885, 2020-10-28 19:57:30 ,      H6502 ,       0,       1\n",
      " 1887, 2020-10-29 13:21:10 ,       H6502,       0,       0\n",
      " 1888, 2020-10-29 14:21:24 ,         Mnb,       0,       0\n",
      " 1889, 2020-10-29 15:05:47 ,       H6502,       0,       1\n",
      " 1890, 2020-10-29 15:36:09 ,       H6502,       1,       1\n",
      " 1891, 2020-10-29 18:10:00 ,       H6502,       0,       1\n",
      " 1892, 2020-10-29 20:34:13 ,       H6502,       0,       2\n",
      " 1893, 2020-10-30 12:26:09 ,         Mnb,       2,       2\n",
      " 1894, 2020-10-30 15:24:17 ,       H6502,       0,       1\n",
      " 1895, 2020-10-30 15:54:42 ,         Mnb,       0,       1\n",
      " 1896, 2020-10-30 16:58:40 ,       H6502,       0,       1\n",
      " 1897, 2020-10-30 19:36:30 ,       H6502,       0,       1\n",
      " 1898, 2020-11-01 13:59:02 ,       H6502,       2,       1\n",
      " 1904, 2020-11-02 13:20:53 ,         Mnb,       1,       1\n",
      " 1905, 2020-11-02 13:51:30 ,         Mnb,       0,       0\n",
      " 1906, 2020-11-02 14:13:50 ,       H6502,       0,       2\n",
      " 1911, 2020-11-02 20:53:12 ,       H6502,       0,       1\n",
      " 1912, 2020-11-03 11:24:41 ,       H6502,       1,       1\n",
      " 1913, 2020-11-03 12:34:59 ,       H6502,       0,       1\n",
      " 1914, 2020-11-03 13:54:28 ,       H6502,       0,       1\n",
      " 1915, 2020-11-03 13:57:22 ,         Mnb,       1,       2\n",
      " 1916, 2020-11-03 17:07:42 ,       H6502,       0,       1\n",
      " 1917, 2020-11-03 17:11:43 ,         Mnb,       0,       1\n",
      " 1918, 2020-11-04 14:34:23 ,       H6502,       0,       1\n",
      " 1919, 2020-11-04 14:56:28 ,       H6502,       1,       1\n",
      " 1920, 2020-11-04 16:29:26 ,       H6502,       0,       1\n",
      " 1921, 2020-11-04 19:11:25 ,       H6502,       0,       1\n",
      " 1922, 2020-11-05 00:05:16 ,       H6502,       0,       1\n",
      " 1923, 2020-11-05 13:25:12 ,         Mnb,       1,       1\n",
      " 1924, 2020-11-05 14:34:54 ,       H6502,       0,       1\n",
      " 1925, 2020-11-05 14:40:50 ,         Mnb,       0,       1\n",
      " 1926, 2020-11-05 16:01:56 ,       H6502,       1,       2\n",
      " 1927, 2020-11-05 17:57:40 ,       H6502,       0,       2\n",
      " 1928, 2020-11-05 19:41:02 ,         Mnb,       0,       1\n",
      " 1929, 2020-11-05 20:30:01 ,       H6502,       0,       1\n",
      " 1930, 2020-11-06 13:23:49 ,         Mnb,       1,       1\n",
      " 1931, 2020-11-06 14:12:20 ,       H6502,       0,       1\n",
      " 1932, 2020-11-06 14:57:49 ,       H6502,       0,       1\n",
      " 1933, 2020-11-06 15:36:05 ,         Mnb,       2,       1\n",
      " 1934, 2020-11-06 15:47:55 ,       H6502,       0,       1\n",
      " 1937, 2020-11-06 19:08:23 ,       H6502,       1,       1\n",
      " 1939, 2020-11-08 11:18:15 ,       H6502,       0,       1\n",
      " 1940, 2020-11-08 12:39:22 ,       H6502,       1,       1\n",
      " 1941, 2020-11-09 12:23:48 ,       H6502,       1,       1\n",
      " 1943, 2020-11-10 13:28:49 ,         Mnb,       1,       1\n",
      " 1944, 2020-11-10 13:44:39 ,       H6502,       1,       1\n",
      " 1945, 2020-11-10 15:58:48 ,         Mnb,       0,       1\n",
      " 1946, 2020-11-10 19:41:11 ,         Mnb,       0,       1\n",
      " 1947, 2020-11-11 13:26:53 ,         Mnb,       2,       2\n",
      " 1948, 2020-11-11 14:51:18 ,         Mnb,       0,       1\n",
      " 1949, 2020-11-11 16:37:31 ,         Mnb,       0,       1\n",
      " 1950, 2020-11-11 19:47:35 ,         Mnb,       0,       1\n",
      " 1951, 2020-11-12 13:05:28 ,       H6502,       0,       1\n",
      " 1955, 2020-11-12 19:40:05 ,       H6502,       1,       2\n",
      " 1956, 2020-11-13 13:24:08 ,         Mnb,       1,       1\n",
      " 1957, 2020-11-13 14:10:30 ,         Mnb,       0,       0\n",
      " 1958, 2020-11-13 15:16:48 ,         Mnb,       0,       1\n",
      " 1959, 2020-11-13 16:54:16 ,         Mnb,       0,       0\n",
      " 1966, 2020-11-16 17:59:18 ,       H6502,       1,       1\n",
      " 1974, 2020-11-18 17:05:43 ,         Mnb,       0,       1\n",
      " 1979, 2020-11-19 14:41:49 ,       H6502,       2,       2\n",
      " 1980, 2020-11-19 14:51:46 ,         Mnb,       0,       1\n",
      " 1982, 2020-11-20 13:30:46 ,         Mnb,       2,       3\n",
      " 1983, 2020-11-20 15:14:50 ,         Mnb,       0,       1\n",
      " 1984, 2020-11-20 15:49:29 ,       H6502,       2,       1\n",
      " 1985, 2020-11-20 17:15:53 ,         Mnb,       0,       1\n",
      " 1989, 2020-11-21 16:09:32 ,       H6502,       1,       2\n",
      " 1990, 2020-11-23 13:34:48 ,         Mnb,       1,       1\n",
      " 1991, 2020-11-23 15:54:19 ,         Mnb,       0,       1\n",
      " 1992, 2020-11-23 21:08:48 ,         RB4,       1,       1\n",
      " 1994, 2020-11-24 13:36:52 ,         Mnb,       2,       1\n"
     ]
    }
   ],
   "source": [
    "# get a list of every human use\n",
    "\n",
    "initial_use_l = 1803\n",
    "last_use_l = 1995\n",
    "use_l = []\n",
    "\n",
    "print(\"   ID,           date/time ,     user_id, stool #, urine #\")\n",
    "conn = sqlite3.connect('data/toilet.db')\n",
    "sql = \"SELECT id, date_time, user_id FROM data_capture where id > {} and id < {}\".format(initial_use_l, last_use_l)\n",
    "cursor = conn.execute(sql)\n",
    "\n",
    "data_capture_dirs = [ f.name for f in os.scandir('./data/data_frames') if f.is_dir() ]\n",
    "\n",
    "for row in cursor:\n",
    "        \n",
    "    # was there a urination event?\n",
    "    urine_sql = \"SELECT timestamp_ms FROM data_start_stop_time WHERE data_capture_id=%d AND type_id=2\" % row[0]\n",
    "    urine_cursor = conn.execute(urine_sql)\n",
    "    urine_l = []\n",
    "    for urine_row in urine_cursor:\n",
    "        urine_l.append(urine_row[0])\n",
    "    #endfor\n",
    "    urine_c = int(len(urine_l)/2)\n",
    "    \n",
    "    # was there a stool event?\n",
    "    stool_sql = \"SELECT timestamp_ms FROM data_start_stop_time WHERE data_capture_id=%d AND type_id=3\" % row[0]\n",
    "    stool_cursor = conn.execute(stool_sql)\n",
    "    stool_l = []\n",
    "    for stool_row in stool_cursor:\n",
    "        stool_l.append(stool_row[0])\n",
    "    #endfor\n",
    "    stool_c = int(len(stool_l)/2)\n",
    "    \n",
    "    # was someone actually sitting on the toilet?\n",
    "    if (len(urine_l) > 0) or (len(stool_l) > 0):\n",
    "        \n",
    "        ##########\n",
    "        # weight # \n",
    "        ##########\n",
    "        \n",
    "        seatWeight_l = []\n",
    "        seatWeight_sql = \"SELECT value FROM data WHERE data_capture_id=%d AND sensor_id=2\" % row[0]\n",
    "        seatWeight_cursor = conn.execute(seatWeight_sql)\n",
    "        for seatWeight_row in seatWeight_cursor:\n",
    "            seatWeight_l.append(seatWeight_row[0])\n",
    "        #endfor\n",
    "        seatWeight_sz = pa.Series(seatWeight_l)\n",
    "        \n",
    "        footWeight_l = []\n",
    "        footWeight_sql = \"SELECT value FROM data WHERE data_capture_id=%d AND sensor_id=3\" % row[0]\n",
    "        footWeight_cursor = conn.execute(footWeight_sql)\n",
    "        for footWeight_row in footWeight_cursor:\n",
    "            footWeight_l.append(footWeight_row[0])\n",
    "        #endfor\n",
    "        footWeight_sz = pa.Series(footWeight_l)\n",
    "        \n",
    "        totalWeight_median = (footWeight_sz.median() + seatWeight_sz.median())/1000\n",
    "\n",
    "        waterDistance_l = []\n",
    "        waterDistance_sql = \"SELECT value FROM data WHERE data_capture_id=%d AND sensor_id=1\" % row[0]\n",
    "        waterDistance_cursor = conn.execute(waterDistance_sql)\n",
    "        for waterDistance_row in waterDistance_cursor:\n",
    "            waterDistance_l.append(waterDistance_row[0])\n",
    "        #endfor\n",
    "        waterDistance_sz = pa.Series(waterDistance_l)\n",
    "\n",
    "        \n",
    "        ##########\n",
    "        # length # \n",
    "        ##########\n",
    "        min_t = np.inf\n",
    "        if len(urine_l) > 0:\n",
    "            if min(urine_l) < min_t: min_t = min(urine_l)\n",
    "        #endif\n",
    "        if len(stool_l) > 0:\n",
    "            if min(stool_l) < min_t: min_t = min(stool_l)\n",
    "        #endif\n",
    "        max_t = 0\n",
    "        if len(urine_l) > 0:\n",
    "            if max(urine_l) > max_t: max_t = max(urine_l)\n",
    "        #endif\n",
    "        if len(stool_l) > 0:\n",
    "            if max(stool_l) > max_t: max_t = max(stool_l)\n",
    "        #endif        \n",
    "        total_t = (max_t-min_t)/1000\n",
    "        \n",
    "        # Get files in directory\n",
    "        files_in_dir = []\n",
    "        if \"data_capture_{}\".format(row[0]) in data_capture_dirs:\n",
    "            files_in_dir = [ f.name for f in os.scandir(\"./data/data_frames/data_capture_{}\".format(row[0])) if f.is_file() ]\n",
    "        \n",
    "        # Get file sizes for files in directory\n",
    "        file_sizes = {}\n",
    "        if len(files_in_dir) > 0:\n",
    "            for f in files_in_dir:\n",
    "                file_sizes[f] = os.stat('./data/data_frames/data_capture_{}/{}'.format(row[0], f)).st_size\n",
    "        \n",
    "        # Filters: Do radar, audio, thermal data files exist and are they non-zero?  \n",
    "        # Is there foot scale data, toilet seat data, ultrasonic data?\n",
    "        # Is median seat weight greater than threshold value (ex. 3kg)? \n",
    "        # Was the ultrasonic sensor working (median greater than threshold and less than a threshold)?\n",
    "        if \"radar_data.txt\" in files_in_dir and \\\n",
    "           \"audio_data.wav\" in files_in_dir and \\\n",
    "           \"thermal_data.txt\" in files_in_dir and \\\n",
    "           file_sizes[\"radar_data.txt\"] > 200 and \\\n",
    "           file_sizes[\"audio_data.wav\"] > 200 and \\\n",
    "           file_sizes[\"thermal_data.txt\"] > 200 and \\\n",
    "           seatWeight_sz.size > 0 and \\\n",
    "           seatWeight_sz.median() > 3  and \\\n",
    "           footWeight_sz.size > 0 and \\\n",
    "           footWeight_sz.median() > 3 and \\\n",
    "           waterDistance_sz.size > 0 and \\\n",
    "           waterDistance_sz.median() > .08 and \\\n",
    "           waterDistance_sz.median() < 2:    \n",
    "            use_l.append(row[0])\n",
    "            user_id = row[2] if row[2] is not None else \"None\"\n",
    "            print(\"{0:5}, {1:20}, {2:>11}, {3:7}, {4:7}\".format(row[0],row[1],user_id,stool_c,urine_c))\n",
    "\n",
    "    #endif\n",
    "#endfor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize each use case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualizing 1806\n",
      "Visualizing 1807\n",
      "Visualizing 1808\n",
      "Visualizing 1817\n",
      "Visualizing 1818\n",
      "Visualizing 1826\n",
      "Visualizing 1828\n",
      "Visualizing 1829\n",
      "Visualizing 1830\n",
      "Visualizing 1831\n",
      "Visualizing 1832\n",
      "Visualizing 1833\n",
      "Visualizing 1834\n",
      "Visualizing 1835\n",
      "Visualizing 1836\n",
      "Visualizing 1839\n",
      "Visualizing 1841\n",
      "Visualizing 1845\n",
      "Visualizing 1854\n",
      "Visualizing 1855\n",
      "Visualizing 1861\n",
      "Visualizing 1862\n",
      "Visualizing 1869\n",
      "Visualizing 1870\n",
      "Visualizing 1871\n",
      "Visualizing 1872\n",
      "Visualizing 1874\n",
      "Visualizing 1875\n",
      "Visualizing 1876\n",
      "Visualizing 1877\n",
      "Visualizing 1878\n",
      "Visualizing 1879\n",
      "Visualizing 1880\n",
      "Visualizing 1881\n",
      "Visualizing 1882\n",
      "Visualizing 1883\n",
      "Visualizing 1884\n",
      "Visualizing 1885\n",
      "Visualizing 1887\n",
      "Visualizing 1888\n",
      "Visualizing 1889\n",
      "Visualizing 1890\n",
      "Visualizing 1891\n",
      "Visualizing 1892\n",
      "Visualizing 1893\n",
      "Visualizing 1894\n",
      "Visualizing 1895\n",
      "Visualizing 1896\n",
      "Visualizing 1897\n",
      "Visualizing 1898\n",
      "Visualizing 1904\n",
      "Visualizing 1905\n",
      "Visualizing 1906\n",
      "Visualizing 1911\n",
      "Visualizing 1912\n",
      "Visualizing 1913\n",
      "Visualizing 1914\n",
      "Visualizing 1915\n",
      "Visualizing 1916\n",
      "Visualizing 1917\n",
      "Visualizing 1918\n",
      "Visualizing 1919\n",
      "Visualizing 1920\n",
      "Visualizing 1921\n",
      "Visualizing 1922\n",
      "Visualizing 1923\n",
      "Visualizing 1924\n",
      "Visualizing 1925\n",
      "Visualizing 1926\n",
      "Visualizing 1927\n",
      "Visualizing 1928\n",
      "Visualizing 1929\n",
      "Visualizing 1930\n",
      "Visualizing 1931\n",
      "Visualizing 1932\n",
      "Visualizing 1933\n",
      "Visualizing 1934\n",
      "Visualizing 1937\n",
      "Visualizing 1939\n",
      "Visualizing 1940\n",
      "Visualizing 1941\n",
      "Visualizing 1943\n",
      "Visualizing 1944\n",
      "Visualizing 1945\n",
      "Visualizing 1946\n",
      "Visualizing 1947\n",
      "Visualizing 1948\n",
      "Visualizing 1949\n",
      "Visualizing 1950\n",
      "Visualizing 1951\n",
      "Visualizing 1955\n",
      "Visualizing 1956\n",
      "Visualizing 1957\n",
      "Visualizing 1958\n",
      "Visualizing 1959\n",
      "Visualizing 1966\n",
      "Visualizing 1974\n",
      "Visualizing 1979\n",
      "Visualizing 1980\n",
      "Visualizing 1982\n",
      "Visualizing 1983\n",
      "Visualizing 1984\n",
      "Visualizing 1985\n",
      "Visualizing 1989\n",
      "Visualizing 1990\n",
      "Visualizing 1991\n",
      "Visualizing 1992\n",
      "Visualizing 1994\n"
     ]
    }
   ],
   "source": [
    "#use_l=[1994]\n",
    "fig_path = '/home/stephen/python/dl_data_downloader/Data/figs'\n",
    "for use_i in use_l:\n",
    "    if use_i > 900:\n",
    "        print(\"Visualizing %d\" % use_i)\n",
    "        PlotUse(use_i,fig_path)\n",
    "    #endif\n",
    "#endif"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PlotUse(use_i,fig_path):\n",
    "\n",
    "    data_d = {}\n",
    "    data_d[1] = GetSensor(use_i,1) # vertical ultrasound\n",
    "    data_d[2] = GetSensor(use_i,2) # seat scale\n",
    "    data_d[3] = GetSensor(use_i,3) # foot scale\n",
    "    thermal_mi = GetThermal2(use_i)  # thermal camera\n",
    "    radar_df = GetRadar(use_i)  # radar\n",
    "    \n",
    "    t0 = data_d[1][0][0]\n",
    "    data_d['urineButton'] = GetEvent(use_i,2)\n",
    "    data_d['stoolButton'] = GetEvent(use_i,3)\n",
    "    stool_l = [float(i-t0)/1000 for i in data_d['stoolButton']]\n",
    "    urine_l = [float(i-t0)/1000 for i in data_d['urineButton']]\n",
    "\n",
    "    event_start_t = np.inf\n",
    "    event_end_t = 0.\n",
    "    if len(stool_l) > 0:\n",
    "        event_start_t =  min(event_start_t,min(stool_l))\n",
    "        event_end_t = max(event_end_t,max(stool_l))\n",
    "    #endif\n",
    "\n",
    "    if len(urine_l) > 0:\n",
    "        event_start_t = min(event_start_t,min(urine_l))\n",
    "        event_end_t = max(event_end_t,max(urine_l))\n",
    "    #endif\n",
    "\n",
    "    clean1_sz, clean2_sz = cleanSensors(data_d[2][0],data_d[2][1],data_d[3][0],data_d[3][1])\n",
    "\n",
    "    if use_i < 945:\n",
    "        fig, (ax1,ax2,ax3,ax4,ax7,ax8,ax9,ax10,ax11,ax12) = plt.subplots(10, sharex=True, figsize=(30,20))\n",
    "    else: # for now, just assume we're only looking at samples that have audio files.\n",
    "        fig, (ax1,ax2,ax3,ax4,ax7,ax8,ax9,ax10,ax11,ax12,ax13,ax14, ax15, ax16) = plt.subplots(14, sharex=True, figsize=(30,20))\n",
    "    #endif\n",
    "    \n",
    "    fig.tight_layout(pad=3.0)\n",
    "    \n",
    "    footSeat_space_n = 4\n",
    "    \n",
    "    axi = ax1\n",
    "    seatScale_sz = clean1_sz/1000\n",
    "    x_ix = (seatScale_sz.index-t0)/1000 #\n",
    "    axi.plot(x_ix,seatScale_sz,linewidth=3) #\n",
    "    axi.xaxis.set_major_formatter(librosa.display.TimeFormatter()) # \n",
    "    axi.tick_params(axis='x', labelbottom=True, labelrotation=90)\n",
    "    \n",
    "    axi.set_ylabel('seat [kg]')\n",
    "    axi.grid()\n",
    "    event_b = (x_ix > event_start_t) & (x_ix < event_end_t) # \n",
    "    event_scale_sz = seatScale_sz[event_b]\n",
    "    axi.set_ylim(seatScale_sz.median()-footSeat_space_n,seatScale_sz.median()+footSeat_space_n)\n",
    "    #axi.set_ylim(0,90)\n",
    "\n",
    "    for i in range(int(len(stool_l)/2)):\n",
    "        x = [stool_l[2*i],stool_l[2*i],stool_l[2*i+1],stool_l[2*i+1]]\n",
    "        y = [0,500,500,0]\n",
    "        axi.fill(x,y, 'red', alpha=0.5)\n",
    "    #endfor\n",
    "    for i in range(int(len(urine_l)/2)):\n",
    "        x = [urine_l[2*i],urine_l[2*i],urine_l[2*i+1],urine_l[2*i+1]]\n",
    "        y = [0,500,500,0]\n",
    "        axi.fill(x,y, 'gold', alpha=0.8)\n",
    "    #endfor\n",
    "\n",
    "    axi = ax2\n",
    "    footScale_sz = clean2_sz/1000\n",
    "    \n",
    "    x_ix = (footScale_sz.index-t0)/1000 #\n",
    "    axi.plot(x_ix,footScale_sz,linewidth=3) #\n",
    "    axi.xaxis.set_major_formatter(librosa.display.TimeFormatter()) # \n",
    "    axi.tick_params(axis='x', labelbottom=True, labelrotation=90)\n",
    "    axi.set_ylabel('footrest [kg]')# \n",
    "    axi.grid() #\n",
    "    event_b = (x_ix > event_start_t) & (x_ix < event_end_t) #   \n",
    "    \n",
    "    event_scale_sz = footScale_sz[event_b]\n",
    "    axi.set_ylim(footScale_sz.median()-footSeat_space_n,footScale_sz.median()+footSeat_space_n)\n",
    "    #axi.set_ylim(0,90)\n",
    "\n",
    "    for i in range(int(len(stool_l)/2)):\n",
    "        x = [stool_l[2*i],stool_l[2*i],stool_l[2*i+1],stool_l[2*i+1]]\n",
    "        y = [0,500,500,0]\n",
    "        axi.fill(x,y, 'red', alpha=0.5)\n",
    "    #endfor\n",
    "    for i in range(int(len(urine_l)/2)):\n",
    "        x = [urine_l[2*i],urine_l[2*i],urine_l[2*i+1],urine_l[2*i+1]]\n",
    "        y = [0,500,500,0]\n",
    "        axi.fill(x,y, 'gold', alpha=0.8)\n",
    "    #endfor\n",
    "\n",
    "    axi = ax3\n",
    "    sumScale_sz = seatScale_sz  + footScale_sz\n",
    "    \n",
    "    x_ix = (sumScale_sz.index-t0)/1000 #\n",
    "    axi.plot(x_ix,sumScale_sz,linewidth=3) #\n",
    "    axi.xaxis.set_major_formatter(librosa.display.TimeFormatter()) # \n",
    "    axi.tick_params(axis='x', labelbottom=True, labelrotation=90)\n",
    "    axi.set_ylabel('sum_scale [kg]')# \n",
    "    event_b = (x_ix > event_start_t) & (x_ix < event_end_t) # \n",
    "    \n",
    "    event_scale_sz = sumScale_sz[event_b]\n",
    "    axi.set_ylim(sumScale_sz.median()-3,sumScale_sz.median()+3)\n",
    "    #axi.set_ylim(75,95)\n",
    "\n",
    "    axi.grid()\n",
    "    for i in range(int(len(stool_l)/2)):\n",
    "        x = [stool_l[2*i],stool_l[2*i],stool_l[2*i+1],stool_l[2*i+1]]\n",
    "        y = [0,500,500,0]\n",
    "        axi.fill(x,y, 'red', alpha=0.5)\n",
    "    #endfor\n",
    "    for i in range(int(len(urine_l)/2)):\n",
    "        x = [urine_l[2*i],urine_l[2*i],urine_l[2*i+1],urine_l[2*i+1]]\n",
    "        y = [0,500,500,0]\n",
    "        axi.fill(x,y, 'gold', alpha=0.8)\n",
    "    #endfor\n",
    "\n",
    "    axi = ax4\n",
    "    data_sz = pa.Series([i*100 for i in data_d[1][1]])\n",
    "\n",
    "    x_ix = [(i-t0)/1000 for i in data_d[1][0]] #\n",
    "    axi.plot(x_ix,data_sz,linewidth=3) #\n",
    "    axi.xaxis.set_major_formatter(librosa.display.TimeFormatter()) # \n",
    "    axi.tick_params(axis='x', labelbottom=True, labelrotation=90)\n",
    "    axi.set_ylabel('water distance [cm]')# \n",
    "    axi.grid() #\n",
    "    \n",
    "    axi.set_ylim(data_sz.median()-1,data_sz.median()+1)\n",
    "    for i in range(int(len(stool_l)/2)):\n",
    "        x = [stool_l[2*i],stool_l[2*i],stool_l[2*i+1],stool_l[2*i+1]]\n",
    "        y = [0,20,20,0]\n",
    "        axi.fill(x,y, 'red', alpha=0.5)\n",
    "    #endfor\n",
    "    for i in range(int(len(urine_l)/2)):\n",
    "        x = [urine_l[2*i],urine_l[2*i],urine_l[2*i+1],urine_l[2*i+1]]\n",
    "        y = [0,20,20,0]\n",
    "        axi.fill(x,y, 'gold', alpha=0.8)\n",
    "    #endfor\n",
    "    x_ax_lim = axi.get_xlim()\n",
    " \n",
    "    axi = ax7\n",
    "    t0_df = thermal_mi.loc[thermal_mi.index[0][0]]\n",
    "    diff_d = {}\n",
    "    for t, df in thermal_mi.groupby(level=0):\n",
    "        diff_d[t] = ((t0_df - thermal_mi.loc[t])**2).sum().sum()\n",
    "    #endfor\n",
    "    \n",
    "    diff_sz = pa.Series(diff_d)\n",
    "    x_ix = (diff_sz.index-t0)/1000 #\n",
    "    axi.plot(x_ix,diff_sz,linewidth=3) #\n",
    "    axi.xaxis.set_major_formatter(librosa.display.TimeFormatter()) # \n",
    "    axi.tick_params(axis='x', labelbottom=True, labelrotation=90)\n",
    "    axi.set_ylabel('infrared camera')#  \n",
    "    \n",
    "    axi.grid()\n",
    "    for i in range(int(len(stool_l)/2)):\n",
    "        x = [stool_l[2*i],stool_l[2*i],stool_l[2*i+1],stool_l[2*i+1]]\n",
    "        y = [0,8000,8000,0]\n",
    "        axi.fill(x,y, 'red', alpha=0.5)\n",
    "    #endfor\n",
    "    for i in range(int(len(urine_l)/2)):\n",
    "        x = [urine_l[2*i],urine_l[2*i],urine_l[2*i+1],urine_l[2*i+1]]\n",
    "        y = [0,8000,8000,0]\n",
    "        axi.fill(x,y, 'gold', alpha=0.8)\n",
    "    #endfor\n",
    "    axi.set_xlim(x_ax_lim)\n",
    "    \n",
    "    # plot thermal camera data\n",
    "    axi = ax8\n",
    "    row_df = thermal_mi.groupby(level=0).mean()\n",
    "    \n",
    "    xval = (row_df.index - t0)/1000\n",
    "    yval = range(8)[::-1]\n",
    "    xx, yy = np.meshgrid(xval, yval)\n",
    "    axi.pcolormesh(xx,yy,row_df.T,edgecolors='face')\n",
    "    axi.set_ylabel('row_infrared')\n",
    "    axi.tick_params(axis='x', labelbottom=True, labelrotation=90)\n",
    "\n",
    "    axi = ax9\n",
    "    column_df = thermal_mi.mean(1).unstack(level=1)\n",
    "    xval = (column_df.index - t0)/1000\n",
    "    yval = range(8)[::-1]\n",
    "    xx, yy = np.meshgrid(xval, yval)\n",
    "    axi.pcolormesh(xx,yy,column_df.T,edgecolors='face')\n",
    "    axi.set_ylabel('column_infrared')\n",
    "    axi.tick_params(axis='x', labelbottom=True, labelrotation=90)\n",
    "\n",
    "    # plot radar data\n",
    "    floor_i = 50\n",
    "    ceil_i = 200\n",
    "    axi = ax10\n",
    "    x0 = (radar_df.columns[0]-t0)/1000\n",
    "    x1 = (radar_df.columns[-1]-t0)/1000\n",
    "    axi.imshow(radar_df.iloc[::-1],aspect='auto',extent=[x0,x1,radar_df.index[0],radar_df.index[-1]])\n",
    "    axi.plot([x0,x1],[floor_i,floor_i],'r-')\n",
    "    axi.plot([x0,x1],[ceil_i,ceil_i],'r-')\n",
    "    axi.set_ylabel('radar')\n",
    "    axi.tick_params(axis='x', labelbottom=True, labelrotation=90)\n",
    "    \n",
    "    axi = ax11\n",
    "    area_d = {}\n",
    "    for i in radar_df.columns:\n",
    "        sq_sz = (radar_df[i])**2\n",
    "        area_d[i] = sum(sq_sz.iloc[floor_i:ceil_i])\n",
    "    #endfor\n",
    "    area_sz = pa.Series(area_d)\n",
    "    x_ix = (area_sz.index-t0)/1000 #\n",
    "    axi.plot(x_ix,area_sz,linewidth=3) #\n",
    "    axi.tick_params(axis='x', labelbottom=True, labelrotation=90)\n",
    "    axi.set_ylabel('radar sum')\n",
    "    axi.set_ylim([0,5e9])\n",
    "    axi.grid()\n",
    "    for i in range(int(len(stool_l)/2)):\n",
    "        x = [stool_l[2*i],stool_l[2*i],stool_l[2*i+1],stool_l[2*i+1]]\n",
    "        y = [0,5e9,5e9,0]\n",
    "        axi.fill(x,y, 'red', alpha=0.5)\n",
    "    #endfor\n",
    "    for i in range(int(len(urine_l)/2)):\n",
    "        x = [urine_l[2*i],urine_l[2*i],urine_l[2*i+1],urine_l[2*i+1]]\n",
    "        y = [0,5e9,5e9,0]\n",
    "        axi.fill(x,y, 'gold', alpha=0.8)\n",
    "    #endfor\n",
    "        \n",
    "          \n",
    "    if use_i < 945:\n",
    "        axi = ax12\n",
    "        S_DB, fs, hop_len = GetAudio1(use_i)\n",
    "        ax = librosa.display.specshow(S_DB, sr=fs, hop_length=hop_len, x_axis='time', y_axis='mel', ax=axi)\n",
    "        axi.set_ylabel('back mic')\n",
    "    elif use_i < 1753: \n",
    "        axi = ax12\n",
    "        S_DB, fs, hop_len = GetAudio2(use_i,\"back\")\n",
    "        ax = librosa.display.specshow(S_DB, sr=fs, hop_length=hop_len, x_axis='time', y_axis='mel', ax=axi)\n",
    "        axi.set_ylabel('back mic')\n",
    "        \n",
    "        axi = ax13\n",
    "        S_DB, fs, hop_len = GetAudio2(use_i,\"front\")\n",
    "        ax = librosa.display.specshow(S_DB, sr=fs, hop_length=hop_len, x_axis='time', y_axis='mel', ax=axi)\n",
    "        axi.set_ylabel('front mic')\n",
    "    else:\n",
    "        axi = ax12\n",
    "        S_DB_front, S_DB_back, fs, hop_len = GetAudio3(use_i)\n",
    "        ax = librosa.display.specshow(S_DB_front, sr=fs, hop_length=hop_len, x_axis='time', y_axis='mel', ax=axi)\n",
    "        axi.set_ylabel('front mic')\n",
    "        axi.tick_params(axis='x', labelbottom=True, labelrotation=90)\n",
    "        \n",
    "        axi = ax13\n",
    "        ax = librosa.display.specshow(S_DB_back, sr=fs, hop_length=hop_len, x_axis='time', y_axis='mel', ax=axi)\n",
    "        axi.set_ylabel('back mic')\n",
    "        axi.tick_params(axis='x', labelbottom=True, labelrotation=90)\n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # Time delay beam forming with stereo microphones\n",
    "    use_dn = \"/home/stephen/python/dl_data_downloader/Data/data/data_frames/data_capture_\" + str(use_i)\n",
    "    back_wav_fn = use_dn + \"/back_audio_data.wav\"\n",
    "    front_wav_fn = use_dn + \"/front_audio_data.wav\"\n",
    "    sampleRate_n = 48000\n",
    "    x_back, fs = librosa.load(back_wav_fn,sr=sampleRate_n)\n",
    "    x_front, fs = librosa.load(front_wav_fn,sr=sampleRate_n)\n",
    "\n",
    "    def frame(data, window_length, hop_length):\n",
    "      \"\"\"Convert array into a sequence of successive possibly overlapping frames.\n",
    "      An n-dimensional array of shape (num_samples, ...) is converted into an\n",
    "      (n+1)-D array of shape (num_frames, window_length, ...), where each frame\n",
    "      starts hop_length points after the preceding one.\n",
    "      This is accomplished using stride_tricks, so the original data is not\n",
    "      copied.  However, there is no zero-padding, so any incomplete frames at the\n",
    "      end are not included.\n",
    "      Args:\n",
    "        data: np.array of dimension N >= 1.\n",
    "        window_length: Number of samples in each frame.\n",
    "        hop_length: Advance (in samples) between each window.\n",
    "      Returns:\n",
    "        (N+1)-D np.array with as many rows as there are complete frames that can be\n",
    "        extracted.\n",
    "      \"\"\"\n",
    "      num_samples = data.shape[0]\n",
    "      num_frames = 1 + int(np.floor((num_samples - window_length) / hop_length))\n",
    "      shape = (num_frames, window_length) + data.shape[1:]\n",
    "      strides = (data.strides[0] * hop_length,) + data.strides\n",
    "      return np.lib.stride_tricks.as_strided(data, shape=shape, strides=strides)\n",
    "    \n",
    "    \n",
    "    EXAMPLE_WINDOW_SECONDS = .1\n",
    "    EXAMPLE_HOP_SECONDS = EXAMPLE_WINDOW_SECONDS     # overlap\n",
    "    window_length = int(round(EXAMPLE_WINDOW_SECONDS * sampleRate_n))\n",
    "    hop_length = int(round(EXAMPLE_HOP_SECONDS * sampleRate_n))\n",
    "\n",
    "    back_frames = frame(x_back,window_length,hop_length)\n",
    "    front_frames = frame(x_front,window_length,hop_length)\n",
    "\n",
    "    frame_n = back_frames.shape[0]\n",
    "\n",
    "    delay_d = {}\n",
    "    delay2_d = {}\n",
    "    ratio = {}\n",
    "\n",
    "    for i in range(frame_n):\n",
    "\n",
    "        back_frame = back_frames[i,:]\n",
    "        back_pad = np.concatenate((back_frame,np.zeros(back_frame.shape)),axis=0)\n",
    "\n",
    "        front_frame = front_frames[i,:]\n",
    "        front_pad = np.concatenate((front_frame,np.zeros(front_frame.shape)),axis=0)\n",
    "\n",
    "        corr_cross = np.fft.ifft(np.fft.fft(front_pad)*np.fft.fft(back_pad[::-1]))\n",
    "        corr_mag = np.abs(corr_cross)\n",
    "        corr_argmax = np.argmax(corr_mag)\n",
    "\n",
    "        delay_d[i] = corr_argmax\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        corr = signal.correlate(back_frame, front_frame, mode='same')\n",
    "        corr_mag = np.abs(corr)\n",
    "        corr_argmax = np.argmax(corr_mag)\n",
    "        num_samples = len(corr)\n",
    "        x = np.arange(-num_samples/2,num_samples/2,1)\n",
    "        delay2_d[i] = -x[corr_argmax]*1/sampleRate_n\n",
    "        \n",
    "        ratio[i] = np.median(np.abs(front_frame))/np.median(np.abs(back_frame))\n",
    "        \n",
    "        \n",
    "    #endfor\n",
    "\n",
    "    delay_sz = pa.Series(delay_d)\n",
    "    delay_x = delay_sz.index*EXAMPLE_WINDOW_SECONDS\n",
    "\n",
    "    # Filter data\n",
    "    window_size= 3\n",
    "    filt_sz = pa.Series(signal.medfilt(delay_sz, window_size))\n",
    "    filt_sz = pa.DataFrame(filt_sz).rolling(window=30).mean()\n",
    "    \n",
    "    axi=ax14\n",
    "    pl.xticks(np.arange(min(delay_x), max(delay_x)+1, 5.0),rotation=90);\n",
    "    #axi.plot(delay_x, delay_sz,linewidth=3)\n",
    "    axi.plot(delay_x, (10000-filt_sz)/1000, linewidth=3)\n",
    "    axi.xaxis.set_major_formatter(librosa.display.TimeFormatter()) # \n",
    "    axi.tick_params(axis='x', labelbottom=True, labelrotation=90)\n",
    "    axi.set_ylabel('mic time delay')# \n",
    "    axi.set_ylim([0,10])\n",
    "    axi.grid() #\n",
    "    \n",
    "    \n",
    "    axi=ax15\n",
    "    \n",
    "    WINDOW_SECONDS = .1  \n",
    "    HOP_SECONDS = WINDOW_SECONDS*.1     # overlap\n",
    "    window_length = int(round(WINDOW_SECONDS * sampleRate_n))\n",
    "    hop_length = int(round(HOP_SECONDS * sampleRate_n))\n",
    "    \n",
    "    back_frames = frame(x_back,window_length,hop_length)\n",
    "    front_frames = frame(x_front,window_length,hop_length)\n",
    "\n",
    "    frame_n = back_frames.shape[0]\n",
    "    \n",
    "    delay2_d = {}\n",
    "\n",
    "    for i in range(frame_n):\n",
    "        back_frame = back_frames[i,:]\n",
    "        front_frame = front_frames[i,:]\n",
    "        corr = signal.correlate(back_frame, front_frame, mode='same')\n",
    "        corr_mag = np.abs(corr)\n",
    "        corr_argmax = np.argmax(corr_mag)\n",
    "        num_samples = len(corr)\n",
    "        x = np.arange(-num_samples/2,num_samples/2,1)\n",
    "        delay2_d[i] = -x[corr_argmax]*1/sampleRate_n\n",
    "    \n",
    "    delay2_sz = pa.Series(delay2_d)\n",
    "    delay2_x = delay2_sz.index*HOP_SECONDS\n",
    "    delay_zero_threshold = delay2_sz.to_numpy()\n",
    "    delay_zero_threshold[delay_zero_threshold < 0] = 0\n",
    "    delay_zero_threshold_sz = pa.Series(delay_zero_threshold)\n",
    "    \n",
    "    window_size = 19\n",
    "    zero_threshold_med_filt_sz = pa.Series(signal.medfilt(delay_zero_threshold_sz, window_size))\n",
    "    sos = butter(3, .005, output='sos')\n",
    "    zero_threshold_lowpass_sz = 2*sosfiltfilt(sos, zero_threshold_med_filt_sz)\n",
    "    sos = butter(3, .1, output='sos')\n",
    "    zero_threshold_lowpass2_sz = sosfiltfilt(sos, zero_threshold_med_filt_sz)\n",
    "    \n",
    "    \n",
    "    pl.xticks(np.arange(min(delay_x), max(delay_x)+1, 5.0),rotation=90);\n",
    "    axi.plot(delay2_x, zero_threshold_lowpass_sz*1000,linewidth=3)\n",
    "    axi.plot(delay2_x, zero_threshold_lowpass2_sz*1000,linewidth=3)\n",
    "    axi.xaxis.set_major_formatter(librosa.display.TimeFormatter()) # \n",
    "    axi.tick_params(axis='x', labelbottom=True, labelrotation=90)\n",
    "    axi.set_ylabel('mic time delay 3')# \n",
    "    axi.set_ylim([-.1,1.5])\n",
    "    axi.grid() #\n",
    "    \n",
    "    axi=ax16\n",
    "    ratio_sz = pa.Series(ratio)\n",
    "    sos = butter(3, .04, output='sos')\n",
    "    lowpass_ratio = sosfiltfilt(sos, ratio_sz)\n",
    "    lowpass_ratio_sz = pa.Series(lowpass_ratio)\n",
    "\n",
    "    pl.xticks(np.arange(min(delay_x), max(delay_x)+1, 5.0),rotation=90);\n",
    "    axi.plot(delay_x, lowpass_ratio_sz,linewidth=3)\n",
    "    axi.xaxis.set_major_formatter(librosa.display.TimeFormatter()) # \n",
    "    axi.tick_params(axis='x', labelbottom=True, labelrotation=90)\n",
    "    axi.set_ylabel('mic ratio')# \n",
    "    axi.set_ylim([.5,4])\n",
    "    axi.grid() #\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    #endif\n",
    "    \n",
    "    axi.xaxis.set_major_locator(plt.MaxNLocator(144))\n",
    "    plt.xticks(rotation=90)\n",
    "    ax1.set_title('{}: {}'.format(use_i,round(sumScale_sz.median(),2)),fontsize=24)\n",
    "    plt.savefig(fig_path + '/' + str(use_i) + '.pdf')\n",
    "    \n",
    "    fig.clf()\n",
    "    plt.close(fig)\n",
    "    gc.collect()\n",
    "#enddef\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetAudio3(use_i):\n",
    "    sampleRate_n = 48000\n",
    "    from scipy.io import wavfile\n",
    "    wav_fn  = 'data/data_frames/data_capture_{}/'.format(use_i) + 'audio_data.wav'\n",
    "    wav_front_fn = 'data/data_frames/data_capture_{}/'.format(use_i) + 'front_audio_data.wav'\n",
    "    wav_back_fn = 'data/data_frames/data_capture_{}/'.format(use_i) + 'back_audio_data.wav'\n",
    "    fs, data = wavfile.read(wav_fn) # reading the file\n",
    "    wavfile.write(wav_front_fn, fs, data[:, 0]) # saving first column which corresponds to channel 1\n",
    "    wavfile.write(wav_back_fn, fs, data[:, 1])  # saving first column which corresponds to channel 1\n",
    "\n",
    "    n_fft = 2048\n",
    "    hop_length = 512\n",
    "    n_mels = 128\n",
    "    \n",
    "    x_front, fs = librosa.load(wav_front_fn,sr=sampleRate_n)\n",
    "    \n",
    "    S_front = librosa.feature.melspectrogram(x_front, sr=sampleRate_n, n_fft=n_fft, \n",
    "                                       hop_length=hop_length, \n",
    "                                       n_mels=n_mels)\n",
    "    S_DB_front = librosa.power_to_db(S_front, ref=np.max)\n",
    "    \n",
    "    x_back, fs = librosa.load(wav_back_fn,sr=sampleRate_n)\n",
    "    \n",
    "    S_back = librosa.feature.melspectrogram(x_back, sr=sampleRate_n, n_fft=n_fft, \n",
    "                                       hop_length=hop_length, \n",
    "                                       n_mels=n_mels)\n",
    "    S_DB_back = librosa.power_to_db(S_back, ref=np.max)\n",
    "\n",
    "    \n",
    "    return S_DB_front, S_DB_back, fs, hop_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetAudio2(use_i,pos_s):\n",
    "    sampleRate_n = 44100\n",
    "    wav_fn  = 'data/data_frames/data_capture_{}/'.format(use_i) + pos_s + '_audio_data.wav'\n",
    "    x, fs = librosa.load(wav_fn,sr=sampleRate_n)\n",
    "\n",
    "    n_fft = 2048\n",
    "    hop_length = 512\n",
    "    n_mels = 128\n",
    "    S = librosa.feature.melspectrogram(x, sr=sampleRate_n, n_fft=n_fft, \n",
    "                                       hop_length=hop_length, \n",
    "                                       n_mels=n_mels)\n",
    "    S_DB = librosa.power_to_db(S, ref=np.max)\n",
    "    return S_DB, fs, hop_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetAudio1(use_i):\n",
    "    sampleRate_n = 96000\n",
    "    wav_fn  = 'data/data_frames/data_capture_{}/audio_data.wav'.format(use_i)\n",
    "    x, fs = librosa.load(wav_fn,sr=sampleRate_n)\n",
    "\n",
    "    n_fft = 2048\n",
    "    hop_length = 512\n",
    "    n_mels = 128\n",
    "    S = librosa.feature.melspectrogram(x, sr=sampleRate_n, n_fft=n_fft, \n",
    "                                       hop_length=hop_length, \n",
    "                                       n_mels=n_mels)\n",
    "    S_DB = librosa.power_to_db(S, ref=np.max)\n",
    "    return S_DB, fs, hop_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetRadar(use_i):\n",
    "\n",
    "    data_fn = 'data/data_frames/data_capture_{}/radar_data.txt'.format(use_i)\n",
    "    data_f = open(data_fn,'rt')\n",
    "    line_s = data_f.read()\n",
    "    data_l = eval(line_s)\n",
    "\n",
    "    # save array of images\n",
    "    t0_sz = pa.Series(data_l[0]['data'])\n",
    "    data_d = {}\n",
    "    for j in range(len(data_l)):\n",
    "        t = data_l[j]['timestamp_ms']\n",
    "        j_sz = pa.Series(data_l[j]['data'][0])\n",
    "        data_d[t] = j_sz\n",
    "    #endfor\n",
    "    data_df = pa.DataFrame(data_d)\n",
    "    return data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetThermal2(use_i):\n",
    "\n",
    "    # read in image text file\n",
    "    thermal_fn = 'data/data_frames/data_capture_{}/thermal_data.txt'.format(use_i)\n",
    "    thermal_f = open(thermal_fn,'rt')\n",
    "    line_s = thermal_f.read()\n",
    "    thermal_l = eval(line_s)\n",
    "\n",
    "    # save array of images\n",
    "    t0_sz = pa.Series(thermal_l[0]['data'])\n",
    "    thermal_d = {}\n",
    "    for j in range(len(thermal_l)):\n",
    "        t = thermal_l[j]['timestamp_ms']\n",
    "        j_df = pa.DataFrame(pa.Series(thermal_l[j]['data']).values.reshape(8,8).T)\n",
    "        thermal_d[t] = j_df\n",
    "    #endfor\n",
    "    thermal_mi = pa.concat(thermal_d.values(),keys=thermal_d.keys())\n",
    "    \n",
    "    return thermal_mi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanSensors(sensor1_t_l,sensor1_y_l,sensor2_t_l,sensor2_y_l):\n",
    "\n",
    "    # get min / max of time-series\n",
    "    #sensor1_t_l = data_d[1][0]\n",
    "    #sensor2_t_l = data_d[2][0]\n",
    "    #sensor1_y_l = data_d[1][1]\n",
    "    #sensor2_y_l = data_d[2][1]\n",
    "    min_t = min(min(sensor1_t_l),min(sensor2_t_l))\n",
    "    max_t = max(max(sensor1_t_l),max(sensor2_t_l))\n",
    "\n",
    "    # setup partitions\n",
    "    step_t = 500\n",
    "    min_floor_t = int(np.floor(min_t/step_t)*step_t)\n",
    "    max_ceil_t = int(np.ceil(max_t/step_t)*step_t)\n",
    "    \n",
    "    step1_d = {}\n",
    "    step2_d = {}\n",
    "    for i in range(min_floor_t,max_ceil_t+step_t,step_t):\n",
    "        step1_d[i] = []\n",
    "        step2_d[i] = []\n",
    "    #endfor\n",
    "\n",
    "    # step through both and assign values to each partition\n",
    "    for i in range(len(sensor1_t_l)):\n",
    "        interval_t = int(np.floor(sensor1_t_l[i]/step_t)*step_t)\n",
    "        step1_d[interval_t].append(sensor1_y_l[i])\n",
    "    #endfor\n",
    "    for i in range(len(sensor2_t_l)):\n",
    "        interval_t = int(np.floor(sensor2_t_l[i]/step_t)*step_t)\n",
    "        step2_d[interval_t].append(sensor2_y_l[i])\n",
    "    #endfor\n",
    "\n",
    "    # step through each partition and either take averages or set to nan\n",
    "    clean1_d = {}\n",
    "    for i in step1_d.keys():\n",
    "        if(len(step1_d[i]) > 0):\n",
    "            clean1_d[i] = np.mean(step1_d[i])\n",
    "    #endfor\n",
    "    clean1_sz = pa.Series(clean1_d)\n",
    "\n",
    "    clean2_d = {}\n",
    "    for i in step2_d.keys():\n",
    "        if(len(step2_d[i]) > 0):\n",
    "            clean2_d[i] = np.mean(step2_d[i])\n",
    "    #endfor\n",
    "    clean2_sz = pa.Series(clean2_d)\n",
    "    \n",
    "    return clean1_sz, clean2_sz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetSensor(use_i,sensor_i):\n",
    "    sql_s = \"SELECT timestamp_ms, value FROM data WHERE data_capture_id={} AND sensor_id={}\".format(use_i,sensor_i)\n",
    "    conn = sqlite3.connect('data/toilet.db')\n",
    "    cursor = conn.execute(sql_s)\n",
    "    time_measurements = []\n",
    "    distance_measurements = []\n",
    "    for row in cursor:\n",
    "        time_measurements.append(row[0])\n",
    "        distance_measurements.append(row[1])\n",
    "    #endfor\n",
    "    data_t = (time_measurements,distance_measurements)\n",
    "    return data_t\n",
    "#enddef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetEvent(use_i,sensor_i):\n",
    "    # was there a urination event?\n",
    "    conn = sqlite3.connect('data/toilet.db')\n",
    "    sql_s = \"SELECT timestamp_ms FROM data_start_stop_time WHERE data_capture_id={} AND type_id={}\".format(use_i,sensor_i)\n",
    "    cursor = conn.execute(sql_s)\n",
    "    time_l = []\n",
    "    for row in cursor:\n",
    "        time_l.append(row[0])\n",
    "    #endfor\n",
    "    return time_l\n",
    "#endfor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
