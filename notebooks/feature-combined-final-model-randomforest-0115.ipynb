{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pa\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from src.utils import get_framed_label, train_test_split\n",
    "from src.data import load_annotation\n",
    "from src.data import load_radar, load_water_distance, load_weight_sensor, load_audio\n",
    "from src import make_dataset\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, plot_roc_curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Urination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'USE_IDS': [],\n",
    "    'DATAFRAME_PATH': \"C:/Users/Jiajun/Desktop/download-project/data/raw/data_frames\",\n",
    "    'ANNOTATION_PATH': \"C:/Users/Jiajun/Desktop/download-project/data/processed/Annotation.csv\",\n",
    "    'FEATURE_NAMES': ['Max', 'Min', 'Mean', 'Median', 'LogVariance', 'LinearTrend'],\n",
    "    'SOURCE_NAMES': ['TotalWeight', 'RadarSum', 'AudioDelay4'],\n",
    "    'WINDOW_SECONDS': 2,\n",
    "    'HOP_SECONDS': 1,\n",
    "    'CATEGORY': \"\",\n",
    "}\n",
    "\n",
    "config['CATEGORY'] = \"Urination\"\n",
    "complete_ids = load_annotation.get_complete_ids(\n",
    "    annotation_filename = config['ANNOTATION_PATH'],\n",
    "    category = config['CATEGORY']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category: Urination\n",
      "Training 48 use_ids: [1891, 1893, 1808, 1906, 1912]...\n",
      "Testing  12 use_ids: [1802, 1806, 1828, 1831, 1832]...\n"
     ]
    }
   ],
   "source": [
    "selected_ids = complete_ids[:60]\n",
    "TRAIN_IDS, TEST_IDS = train_test_split(selected_ids)\n",
    "\n",
    "print(f\"Category: {config['CATEGORY']}\")\n",
    "print(f\"Training {len(TRAIN_IDS)} use_ids: {TRAIN_IDS[:5]}...\")\n",
    "print(f\"Testing  {len(TEST_IDS)} use_ids: {TEST_IDS[:5]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_config = config.copy()\n",
    "test_config = config.copy()\n",
    "\n",
    "train_config['USE_IDS'] = TRAIN_IDS\n",
    "test_config['USE_IDS'] = TEST_IDS\n",
    "\n",
    "dataset = {}\n",
    "dataset['train'] = make_dataset.RandomForestExtended(train_config)\n",
    "dataset['test'] = make_dataset.RandomForestExtended(test_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "updating 1891\n",
      "updating 1893\n",
      "updating 1808\n",
      "updating 1906\n",
      "updating 1912\n",
      "updating 1896\n",
      "updating 1884\n",
      "updating 1887\n",
      "updating 1892\n",
      "updating 1878\n",
      "updating 1875\n",
      "updating 1915\n",
      "updating 1898\n",
      "updating 1818\n",
      "updating 1877\n",
      "updating 1888\n",
      "updating 1870\n",
      "updating 1833\n",
      "updating 1914\n",
      "updating 1863\n",
      "updating 1894\n",
      "updating 1918\n",
      "updating 1854\n",
      "updating 1882\n",
      "updating 1911\n",
      "updating 1883\n",
      "updating 1904\n",
      "updating 1890\n",
      "updating 1917\n",
      "updating 1836\n",
      "updating 1871\n",
      "updating 1913\n",
      "updating 1881\n",
      "updating 1885\n",
      "updating 1874\n",
      "updating 1826\n",
      "updating 1839\n",
      "updating 1880\n",
      "updating 1879\n",
      "updating 1916\n",
      "updating 1920\n",
      "updating 1862\n",
      "updating 1921\n",
      "updating 1864\n",
      "updating 1876\n",
      "updating 1829\n",
      "updating 1897\n",
      "updating 1830\n",
      "updating 1802\n",
      "updating 1806\n",
      "updating 1828\n",
      "updating 1831\n",
      "updating 1832\n",
      "updating 1834\n",
      "updating 1835\n",
      "updating 1841\n",
      "updating 1845\n",
      "updating 1889\n",
      "updating 1895\n",
      "updating 1919\n"
     ]
    }
   ],
   "source": [
    "train_x, train_y = dataset['train'].get_features_and_labels_from_users()\n",
    "test_x, test_y = dataset['test'].get_features_and_labels_from_users()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4790, 402), (1072, 402))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape, test_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(742, (4790,), 194, (1072,))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y.sum(), train_y.shape, test_y.sum(), test_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_estimators=30)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators = 30)\n",
    "rf.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification_result(model, testX, testY, threshold = 0.5):\n",
    "    testYPredProb = model.predict_proba(testX)\n",
    "    testYPred = (testYPredProb[:, 1] > threshold).astype(int)\n",
    "    print (f\"threshold = {threshold}\", \"\\n\")\n",
    "    print (classification_report(testY, testYPred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threshold = 0.3 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.98       878\n",
      "           1       0.92      0.85      0.88       194\n",
      "\n",
      "    accuracy                           0.96      1072\n",
      "   macro avg       0.94      0.91      0.93      1072\n",
      "weighted avg       0.96      0.96      0.96      1072\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classification_result(\n",
    "    rf,\n",
    "    test_x, test_y,\n",
    "    threshold = 0.3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threshold = 0.2 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.97       878\n",
      "           1       0.87      0.90      0.88       194\n",
      "\n",
      "    accuracy                           0.96      1072\n",
      "   macro avg       0.92      0.93      0.93      1072\n",
      "weighted avg       0.96      0.96      0.96      1072\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classification_result(\n",
    "    rf,\n",
    "    test_x, test_y,\n",
    "    threshold = 0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "randomforest-20210108-032342.pkl\n",
      "randomforest-defecate-20210111-034703.pkl\n",
      "randomforest-defecate-20210111-155654.pkl\n",
      "seq2seq-20210107-164232.pt\n",
      "seq2seq-20210107-203845.pt\n",
      "seq2seq-20210108-140539.pt\n",
      "urination-rf-sources-extended-embedding-0202.pkl\n"
     ]
    }
   ],
   "source": [
    "!ls ../models/trained_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"../models/trained_models/urination-rf-sources-extended-embedding-0202.pkl\", \"wb\") as f:\n",
    "    pickle.dump(rf, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defecation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'USE_IDS': [],\n",
    "    'DATAFRAME_PATH': \"C:/Users/Jiajun/Desktop/download-project/data/raw/data_frames\",\n",
    "    'ANNOTATION_PATH': \"C:/Users/Jiajun/Desktop/download-project/data/processed/Annotation.csv\",\n",
    "    'FEATURE_NAMES': ['Max', 'Min', 'Mean', 'Median', 'LogVariance', 'LinearTrend'],\n",
    "    'SOURCE_NAMES': ['TotalWeight', 'RadarSum', 'AudioDelay4'],\n",
    "    'WINDOW_SECONDS': 2,\n",
    "    'HOP_SECONDS': 1,\n",
    "    'CATEGORY': \"Defecation\",\n",
    "}\n",
    "\n",
    "complete_ids = load_annotation.get_complete_ids(\n",
    "    annotation_filename = config['ANNOTATION_PATH'],\n",
    "    category = config['CATEGORY']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category: Defecation\n",
      "Training 23 use_ids: [1898, 1930, 1919, 1926, 1941]...\n",
      "Testing  6 use_ids: [1854, 1870, 1875, 1882, 1890]...\n"
     ]
    }
   ],
   "source": [
    "selected_ids = [idx for idx in complete_ids if idx <= 1950 and idx >= 1800]\n",
    "TRAIN_IDS, TEST_IDS = train_test_split(selected_ids)\n",
    "\n",
    "print(f\"Category: {config['CATEGORY']}\")\n",
    "print(f\"Training {len(TRAIN_IDS)} use_ids: {TRAIN_IDS[:5]}...\")\n",
    "print(f\"Testing  {len(TEST_IDS)} use_ids: {TEST_IDS[:5]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_config = config.copy()\n",
    "test_config = config.copy()\n",
    "\n",
    "train_config['USE_IDS'] = TRAIN_IDS\n",
    "test_config['USE_IDS'] = TEST_IDS\n",
    "\n",
    "dataset = {}\n",
    "dataset['train'] = make_dataset.RandomForestExtended(train_config)\n",
    "dataset['test'] = make_dataset.RandomForestExtended(test_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "updating 1898\n",
      "updating 1930\n",
      "updating 1919\n",
      "updating 1926\n",
      "updating 1941\n",
      "updating 1923\n",
      "updating 1831\n",
      "updating 1881\n",
      "updating 1937\n",
      "updating 1933\n",
      "updating 1839\n",
      "updating 1830\n",
      "updating 1940\n",
      "updating 1862\n",
      "updating 1915\n",
      "updating 1893\n",
      "updating 1863\n",
      "updating 1943\n",
      "updating 1806\n",
      "updating 1912\n",
      "updating 1802\n",
      "updating 1904\n",
      "updating 1947\n",
      "updating 1854\n",
      "updating 1870\n",
      "updating 1875\n",
      "updating 1882\n",
      "updating 1890\n",
      "updating 1944\n"
     ]
    }
   ],
   "source": [
    "train_x, train_y = dataset['train'].get_features_and_labels_from_users()\n",
    "test_x, test_y = dataset['test'].get_features_and_labels_from_users()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x.shape: (3584, 402) test_x.shape: (1065, 402)\n",
      "No. Positive in training 160/(3584,)\n",
      "No. Positive in testing  37/(1065,)\n"
     ]
    }
   ],
   "source": [
    "print(f'train_x.shape: {train_x.shape} test_x.shape: {test_x.shape}')\n",
    "print(f'No. Positive in training {train_y.sum()}/{train_y.shape}')\n",
    "print(f'No. Positive in testing  {test_y.sum()}/{test_y.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(class_weight='balanced', n_estimators=10)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(\n",
    "    n_estimators = 10,\n",
    "    class_weight = \"balanced\"\n",
    ")\n",
    "rf.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification_result(model, testX, testY, threshold = 0.5):\n",
    "    testYPredProb = model.predict_proba(testX)\n",
    "    testYPred = (testYPredProb[:, 1] > threshold).astype(int)\n",
    "    print (f\"threshold = {threshold}\", \"\\n\")\n",
    "    print (classification_report(testY, testYPred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threshold = 0.3 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      1028\n",
      "           1       0.67      0.84      0.75        37\n",
      "\n",
      "    accuracy                           0.98      1065\n",
      "   macro avg       0.83      0.91      0.87      1065\n",
      "weighted avg       0.98      0.98      0.98      1065\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classification_result(\n",
    "    rf,\n",
    "    test_x, test_y,\n",
    "    threshold = 0.3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threshold = 0.4 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      1028\n",
      "           1       0.77      0.62      0.69        37\n",
      "\n",
      "    accuracy                           0.98      1065\n",
      "   macro avg       0.88      0.81      0.84      1065\n",
      "weighted avg       0.98      0.98      0.98      1065\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classification_result(\n",
    "    rf,\n",
    "    test_x, test_y,\n",
    "    threshold = 0.4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('../models/trained_models/defecation-rf-sources-extended-embedding-0202.pkl', 'wb') as f:\n",
    "    pickle.dump(rf, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def variable_importance(trainX, model, top=30):\n",
    "    plt.figure(figsize=(20, 5))\n",
    "    plt.bar(x = range(top), height = model.feature_importances_[:top])\n",
    "    xticks_pos = np.arange(top)\n",
    "    plt.xticks(xticks_pos, trainX.columns[:top], rotation=45, ha = 'right')\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variable_importance(train_x, rf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".download-project",
   "language": "python",
   "name": ".download-project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
